function [p2pModel,trainingPlot] = train(inData, outData, options,Timedata)
% train     Train a pix2pix model.
%
%   A pix2pix model that attempts to learn how to convert images from
%   inData to outData is trained, following the approach described in
%   'Isola et al. Image-to-Image Translation with Conditional Adversarial 
%   Nets'.
%
% Args:
%   inData  - Training data input images 输入的训练文件夹路径，变化前图像
%   outData - Training data target images 输入的训练文件夹路径，变化后的图像
%   options - Training options as a struct generated by
%   p2p.trainingOptions 训练细节参数设定
%   
%
% Returns:
%   p2pModel - A struct containing trained newtorks and optimisiers
%           返回的结构体p2pModel包含了训练的模型和相关参数
%
% See also: p2p.trainingOptions

% Copyright 2020 The MathWorks, Inc.
    
%%预处理
%判断输入参数数量，如果输出参数量小于3，则利用默认选项


%判断是否使用GPU训练，如果是GPU训练，env代表应用gpuArray（）输入参数，否者，直接使用该参数

    if (options.ExecutionEnvironment == "auto" && canUseGPU) || ...
            options.ExecutionEnvironment == "gpu"
        env = @gpuArray;
    else
        env = @(x) x;
    end

% 如果没有设置断点储存路径，设置断点储存路径
    if ~isempty(options.CheckpointPath)
        % Make a subfolder for storing checkpoints
        timestamp = strcat("p2p-", datestr(now, 'yyyymmdd-HHMMSS'));
        checkpointSubDir = fullfile(options.CheckpointPath, timestamp);
        mkdir(checkpointSubDir)
    end

%输入输出通道合并
    combinedChannels = options.InputChannels + options.OutputChannels;
    
    %打乱顺序并迷你批处理，返回的是结构体,该结构体继承了Datastore的定义与接口
    % model learns A to B mapping
    imageAndLabel = p2p.data.PairedImageDatastore(inData, outData, options.MiniBatchSize, ...
        "PreSize", options.PreSize, "CropSize", options.InputSize, "RandXReflection", options.RandXReflection);
  
    %如果需要展示训练过程
    if options.Plots == "training-progress"
        examples = imageAndLabel.shuffle();
        nExamples = 1;
        examples.MiniBatchSize = nExamples;
        data = examples.read();
        thisInput = cat(3, data.dataA{:});%将所有子集在第3个维度拼接起来
        exampleInputs = dlarray(env(thisInput), 'SCB');%按SCB的格式输出到深度学习网络
        trainingPlot = p2p.vis.TrainingPlot(exampleInputs,Timedata);
    end
    
    if isempty(options.ResumeFrom)%如果ResumeFrom为空，则利用参数设置建立量类模型
        g=FtoF_Net();
        d = p2p.networks.discriminator(options.InputSize, combinedChannels, options.DDepth);
        
        %设置优化器
        gOptimiser = p2p.util.AdamOptimiser(options.GLearnRate, options.GBeta1, options.GBeta2);
        dOptimiser = p2p.util.AdamOptimiser(options.DLearnRate, options.DBeta1, options.DBeta2);
        
        iteration = 0;
        startEpoch = 1;
    else%如果是二次训练
        data = load(options.ResumeFrom, 'p2pModel');
        g = data.p2pModel.g;
        d = data.p2pModel.d;
        gOptimiser = data.p2pModel.gOptimiser;
        dOptimiser = data.p2pModel.dOptimiser;
        
        iteration = gOptimiser.Iteration;
        startEpoch = floor(iteration/imageAndLabel.NumObservations)+1;
    end
    
    %% Training loop
    for epoch = startEpoch:options.MaxEpochs
        
        imageAndLabel = imageAndLabel.shuffle();
       
        while imageAndLabel.hasdata
            
            iteration = iteration + 1;
            
            data = imageAndLabel.read();%read里面已经调整和归一化好了
            thisInput = cat(3, data.dataA{:});
            thisTarget = cat(3, data.dataB{:});
            
            input = dlarray(env(thisInput), 'SCB');
            target = dlarray(env(thisTarget), 'SCB');
            
            [g, gLoss, d, dLoss, lossL2, ganLoss, ~] = ...
                dlfeval(@stepBoth, g, d, gOptimiser, dOptimiser, input, target, options);
            
            if mod(iteration, options.VerboseFrequency) == 0
                logArgs = {epoch, iteration,  ...
                    gLoss, lossL2, ganLoss, dLoss};
                fprintf('epoch: %d, it: %d, G: %f (L2: %f, GAN: %f), D: %f\n', ...
                    logArgs{:});
                if options.Plots == "training-progress"
                    trainingPlot.update(logArgs{:}, g);
                end
            end
        end
        
        %构建结构体输出
        p2pModel = struct('g', g, 'd', d, 'gOptimiser', gOptimiser, 'dOptimiser', dOptimiser);

        %定点存档
        if ~isempty(options.CheckpointPath) && mod(epoch,25)==0
            checkpointFilename = sprintf('p2p_checkpoint_%s_%04d.mat', datestr(now, 'YYYY-mm-DDTHH-MM-ss'), epoch);
            p2pModel = gather(p2pModel);
            save(fullfile(checkpointSubDir, checkpointFilename), 'p2pModel')
        end
    end
end

function [g, gLoss, d, dLoss, lossL2, ganLoss, images] = stepBoth(g, d, gOpt, dOpt, inputImage, targetImage, options)
    
    % Make a fake image
    fakeImage = tanh(g.forward(inputImage));
    
    %% D update
    % Apply the discriminator，输出样本和真实样本都经过了sigmoid处理
    realPredictions = sigmoid(d.forward(...
        cat(2, targetImage, inputImage) ...
        ));
    fakePredictions = sigmoid(d.forward(...
        cat(2, fakeImage, inputImage)...
        ));
    
    % calculate D losses
    labels = ones(size(fakePredictions), 'single');
    % crossentropy divides by nBatch, so we need to divide further
    dLoss = options.DRelLearnRate*(crossentropy(realPredictions, labels)/numel(fakePredictions(:,:,1,1)) + ...
        crossentropy(1-fakePredictions, labels)/numel(fakePredictions(:,:,1,1)));
    
    % get d gradients
    dGrads = dlgradient(dLoss, d.Learnables, "RetainData", true);
    dLoss = extractdata(dLoss);
    
    %% G update
    % to save time I just use the existing result from d
    
    % calculate g Losses
    ganLoss = crossentropy(fakePredictions, labels)/numel(fakePredictions(:,:,1,1));
    lossL2 = mean(abs(fakeImage - targetImage).^2, 'all');
    gLoss = options.Lambda*lossL2 + ganLoss;
    
    % get g grads
    gGrads = dlgradient(gLoss, g.Learnables);
    
    % update g
    g.Learnables = dOpt.update(g.Learnables, gGrads);
    % update d
    d.Learnables = gOpt.update(d.Learnables, dGrads);
    % things for plotting
    gLoss = extractdata(gLoss);
    lossL2 = extractdata(lossL2);
    ganLoss = extractdata(ganLoss);
    
    images = {fakeImage, inputImage, targetImage};
end
